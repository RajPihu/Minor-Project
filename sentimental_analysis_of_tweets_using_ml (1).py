# -*- coding: utf-8 -*-
"""Sentimental Analysis of Tweets using ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wsa-O6BU96ULZdzzA0OxtmLz6iYWk8mz
"""

!pip install kaggle

"""# Upload kaggle.json file"""

#configuring the path of kaggle.json file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""## Importing Twitter Sentiment dataset"""

#API to fetch the dataset from kaggle

!kaggle datasets download -d kazanova/sentiment140

# extracting the compressed dataset

from zipfile import ZipFile
dataset = '/content/sentiment140.zip'

with ZipFile(dataset,'r') as zip:
  zip.extractall()
  print('The dataset is extracted')

"""## Importing the Dependencies"""

import numpy as np
import pandas as pd
import re #regular expression
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

import nltk
nltk.download('stopwords')

#printing the stopwords in English
print(stopwords.words('english'))

"""## Data Preprocessing"""

#Loading the data from csv file to pandas dataframe
twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv',encoding='latin-1',header=None)

# checking gth number of rows and columns
twitter_data.shape

#printing the first 5 rows of the dataframe
twitter_data.head()

# naming the columns and reading the dataset again

column_names = ['target','ids','date','flag','user','text']
twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv',encoding='latin-1',header=None,names=column_names)

#checkin gthe number of rows and coumns
twitter_data.shape

#printing the first 5 rows of the dataframe
twitter_data.head()

# counting the number of missing values in the dataset
twitter_data.isnull().sum()

# checking the distributing of target column
twitter_data.target.value_counts()

"""## Convert the target "4" to "1"
"""

twitter_data['target'] = twitter_data['target'].replace(4,1)

#checking the distribution of target column
twitter_data.target.value_counts()

"""## 0 ->Negative Tweet
  ## 1 ->Positive Tweet

# Stemming

Stemming is the process of reducing a word to its Root word

example:actor,actress,acting = act
"""

port_stem = PorterStemmer()

def stemming(content):
  stemmed_content = re.sub('[^a-zA-Z]',' ',content)
  stemmed_content = stemmed_content.lower()
  stemmed_content = stemmed_content.split()
  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
  stemmed_content = ' '.join(stemmed_content)
  return stemmed_content

twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming) #50 minutes to complete thus execution

twitter_data.head()

print(twitter_data['stemmed_content'])

print(twitter_data['target'])

# separating the data and label
x = twitter_data['stemmed_content'].values
y = twitter_data['target'].values

print(x)

print(y)

"""# Splitting the data to training data and test data"""

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y,random_state=2)

print(x.shape,x_train.shape,x_test.shape)

print(x_train)

# Converting the textual data to numerical data

vectorizer = TfidfVectorizer()
vectorizer.fit(x_train)

x_train = vectorizer.transform(x_train)
x_test = vectorizer.transform(x_test)

print(x_train)

"""## Training the Machine Learning model

## Logistic Regression
"""

model = LogisticRegression(max_iter=1000)

model.fit(x_train,y_train)

"""## Model Evaluation

Accuracy Score
"""

#accuracy score on the training data
from sklearn.metrics import accuracy_score

x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction,y_train)

print('Accuracy score of the training data : ',training_data_accuracy)

#aacuracy score of the test data
x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(x_test_prediction,y_test)

print('Accuracy score of the test data : ',test_data_accuracy)

"""Model accuracy=77.6%

## Saving the trained model
"""

import pickle

filename = 'trained_model.sav'
pickle.dump(model,open(filename,'wb'))

"""# Using the saved model for future predictions"""

#loading the saved model
load_ace_data = pickle.load(open('/content/trained_model.sav','rb'))

x_new =x_test[200]
print(y_test[200])

prediction = model.predict(x_new)
print(prediction)

if (prediction[0]==0):
  print('The news is Negative')
else:
  print('The news is Positive')

x_new =x_test[3]
print(y_test[3])

prediction = model.predict(x_new)
print(prediction)

if (prediction[0]==0):
  print('Negative Tweet')
else:
  print('Positive Tweet')